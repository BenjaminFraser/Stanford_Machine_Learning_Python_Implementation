{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam classification of emails\n",
    "\n",
    "- Preprocessing stages carried out in standard Python to illustrate required stages\n",
    "\n",
    "- Scikit-Learn Linear Support Vector Machine used for classifying spam / non-spam emails\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Preview an example email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Anyone knows how much it costs to host a web portal ?\n",
      ">\n",
      "Well, it depends on how many visitors you're expecting.\n",
      "This can be anywhere from less than 10 bucks a month to a couple of $100. \n",
      "You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \n",
      "if youre running something big..\n",
      "\n",
      "To unsubscribe yourself from this mailing list, send an email to:\n",
      "groupname-unsubscribe@egroups.com\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('machine-learning-ex6/ex6/emailSample1.txt','r')\n",
    "email_contents = f.read()\n",
    "f.close()\n",
    "\n",
    "print(email_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Email Preprocessing Steps\n",
    "\n",
    "We want to perform a wide variety of preprocessing steps on our email data before it is suitable for training through a classifier such as a Support Vector Machine.\n",
    "\n",
    "The following will be performed on our data prior to training:\n",
    "- Remove any html formatting present in the email\n",
    "- Convert all numbers given into the string 'number' (in most cases the actual number is irrelevant to our model)\n",
    "- Convert all email addresses into the string 'emailaddr' (the address does not help our predictions in this case)\n",
    "- Convert dollar signs ($) into 'dollar', and pound signs (£) into 'pounds'\n",
    "- Convert all URLs into 'httpaddr'\n",
    "- Remove special symbols or non-alphanumeric characters\n",
    "- Perform word stemming on all words \n",
    "\n",
    "Following this, we will form a binary word vector for a specified vocabulary of 1899 words, which will be used to create features for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_html(contents):\n",
    "    # remove any html present\n",
    "    parser = re.compile(r'<.*?>')\n",
    "    return re.sub(parser, '', contents)\n",
    "\n",
    "def remove_special_chars(contents):\n",
    "    # remove all but alphanumeric chars and spaces\n",
    "    return re.sub('[^A-Za-z0-9]+', ' ', contents)\n",
    "    \n",
    "def handle_numbers(contents):\n",
    "    numbers = re.compile('[0-9]+')\n",
    "    return re.sub(numbers, 'number', contents)\n",
    "\n",
    "def handle_emails(contents):\n",
    "    emails = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    return re.sub(emails, 'emailaddr', contents)\n",
    "\n",
    "def handle_currency(contents):\n",
    "    formatted = contents.replace('$', 'dollar')\n",
    "    formatted = formatted.replace('£', 'pounds')\n",
    "    return formatted\n",
    "\n",
    "def handle_urls(contents):\n",
    "    urls = re.compile('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+')\n",
    "    return re.sub(urls, 'httpaddr', contents)\n",
    "\n",
    "def stem_words(contents):\n",
    "    \"\"\" Stem words using nltk porter stemmer \"\"\"\n",
    "    words = contents.split()\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    words = [str(stemmer.stem(word)) for word in words]\n",
    "    return words\n",
    "    \n",
    "def preprocess_email(email):\n",
    "    \"\"\" Call all our preprocessing steps on the provided email \"\"\"\n",
    "    email_contents = remove_html(email)\n",
    "    email_contents = handle_emails(email_contents)\n",
    "    email_contents = handle_urls(email_contents)\n",
    "    email_contents = handle_numbers(email_contents)\n",
    "    email_contents = handle_currency(email_contents)\n",
    "    email_contents = remove_special_chars(email_contents)\n",
    "    email_contents = email_contents.strip().lower()\n",
    "    stemmed_words = stem_words(email_contents)\n",
    "    return stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate our preprocessing works on our sample email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The words we now have after preprocessing are: \n",
      "\n",
      "['anyon', 'know', 'how', 'much', 'it', 'cost', 'to', 'host', 'a', 'web', 'portal', 'well', 'it', 'depend', 'on', 'how', 'mani', 'visitor', 'you', 're', 'expect', 'thi', 'can', 'be', 'anywher', 'from', 'less', 'than', 'number', 'buck', 'a', 'month', 'to', 'a', 'coupl', 'of', 'dollarnumb', 'you', 'should', 'checkout', 'httpaddr', 'or', 'perhap', 'amazon', 'ecnumb', 'if', 'your', 'run', 'someth', 'big', 'to', 'unsubscrib', 'yourself', 'from', 'thi', 'mail', 'list', 'send', 'an', 'email', 'to', 'emailaddr']\n"
     ]
    }
   ],
   "source": [
    "word_list = preprocess_email(email_contents)\n",
    "print(\"The words we now have after preprocessing are: \\n\\n{}\".format(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Only basic stemmed words remain from our email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create binary word feature vector\n",
    "\n",
    "Now we need to use the provided vocabulary list to keep only those words that occur frequently (since rare words can disrupt our model with such a small amount of data in this case).\n",
    "\n",
    "In practice, our vocabulary list would be much larger (10,000 - 50,000), however for this exercise only 1899 words are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read vocabulary list with pandas and convert into a python dict for lookup\n",
    "vocabulary_file = pd.read_csv('machine-learning-ex6/ex6/vocab.txt', sep=\"\\t\", header=None)\n",
    "vocabulary_file.columns = [\"index\", \"word\"]\n",
    "vocabulary_file.set_index('index')\n",
    "\n",
    "# create a lookup dict of words we want and index values\n",
    "vocab_dict = dict(zip(vocabulary_file[\"word\"], vocabulary_file[\"index\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map each word to its index from the vocab dict - if word is not in vocab list: ignore\n",
    "word_vector = []\n",
    "\n",
    "for word in word_list:\n",
    "    word_index = vocab_dict.get(word)\n",
    "    if word_index:\n",
    "        word_vector.append(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86, 916, 794, 1077, 883, 370, 1699, 790, 1822, 1831, 883, 431, 1171, 794, 1002, 1893, 1364, 592, 1676, 238, 162, 89, 688, 945, 1663, 1120, 1062, 1699, 375, 1162, 479, 1893, 1510, 799, 1182, 1237, 810, 1895, 1440, 1547, 181, 1699, 1758, 1896, 688, 1676, 992, 961, 1477, 71, 530, 1699, 531]\n"
     ]
    }
   ],
   "source": [
    "print(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# also create a binary feature vector: 1 if word is in email, 0 if not\n",
    "feature_vector = []\n",
    "\n",
    "for index in vocabulary_file[\"index\"]:\n",
    "    if index in word_vector:\n",
    "        feature_vector.append(1)\n",
    "    else:\n",
    "        feature_vector.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the feature vector (should be 1899): 1899\n",
      "Number of non-zero entries in example email (should be 45): 45\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the feature vector (should be 1899): {}\".format(len(feature_vector)))\n",
    "\n",
    "print(\"Number of non-zero entries in example email (should be 45): {}\".format(\n",
    "    len([x for x in feature_vector if x == 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know our code successfully creates our word vectors, we can define a function that makes performing these steps easier for training our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorise_words(word_list):\n",
    "    word_vector = []\n",
    "    \n",
    "    # map each word to index from vocab dict - if word not in vocab dict: ignore\n",
    "    for word in word_list:\n",
    "        word_index = vocab_dict.get(word)\n",
    "        if word_index:\n",
    "            word_vector.append(word_index)\n",
    "        \n",
    "    feature_vector = []\n",
    "    \n",
    "    # create a binary feature vector: 1 if word is in email, 0 if not\n",
    "    for index in vocabulary_file[\"index\"]:\n",
    "        if index in word_vector:\n",
    "            feature_vector.append(1)\n",
    "        else:\n",
    "            feature_vector.append(0)\n",
    "    \n",
    "    return word_vector, feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our feature vectors can be obtained using our defined preprocessing steps, we're ready to train a SVM linear classifier to predict whether an email is spam (output 1) or non-spam (output 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SVM Classifier\n",
    "\n",
    "#### With our preprocessing steps complete, we can now train an SVM with linear kernel on our preprocessed data\n",
    "\n",
    "We'll use 4000 preprocessed emails (containing spam and non-spam examples), and 1000 preprocessed emails for testing purposes (containing both spam and non-spam).\n",
    "\n",
    "Each email has been processed using the email preprocessing steps defined above, and structured as a feature vector:\n",
    "\n",
    "$$ x^{(i)} \\in \\Re^{(1899)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (4000, 1899)\n",
      "The shape of X test is: (1000, 1899)\n",
      "The shape of y is: (4000,)\n",
      "The shape of y test is: (1000,)\n"
     ]
    }
   ],
   "source": [
    "train_datafile = loadmat('machine-learning-ex6/ex6/spamTrain.mat', struct_as_record=False)\n",
    "X = train_datafile['X']\n",
    "y = train_datafile['y'].flatten()\n",
    "\n",
    "test_datafile = loadmat('machine-learning-ex6/ex6/spamTest.mat', struct_as_record=False)\n",
    "X_test = test_datafile['Xtest']\n",
    "y_test = test_datafile['ytest'].flatten()\n",
    "\n",
    "print(\"The shape of X is: {}\".format(X.shape))\n",
    "print(\"The shape of X test is: {}\".format(X_test.shape))\n",
    "print(\"The shape of y is: {}\".format(y.shape))\n",
    "print(\"The shape of y test is: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Linear SVM accuracies: Training set: 0.99825, Test set: 0.989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=0.1, kernel='linear').fit(X, y)\n",
    "\n",
    "training_score = clf.score(X, y)\n",
    "test_score = clf.score(X_test, y_test)\n",
    "print(\"The Linear SVM accuracies: Training set: {0}, Test set: {1}\".format(training_score, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection of the top predictors for an email being spam\n",
    "\n",
    "We can analyse the largest coefficients in our trained classifier to see what words have the most impact on an email being classified as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dollarac\n",
      "wall\n",
      "script\n",
      "cv\n",
      "air\n",
      "hot\n",
      "futur\n",
      "ll\n",
      "natur\n",
      "mortgag\n",
      "player\n",
      "previous\n",
      "wife\n",
      "doesn\n",
      "base\n",
      "visa\n",
      "gt\n",
      "remot\n",
      "clearli\n",
      "otherwis\n"
     ]
    }
   ],
   "source": [
    "# get the index of the top 20 classifier coefficients\n",
    "predictors = np.argsort(clf.coef_)\n",
    "top_predicts = predictors[0][-20:].tolist()\n",
    "\n",
    "# create a dict for word index look-up for convenience\n",
    "word_index_dict = dict(zip(vocabulary_file[\"index\"], vocabulary_file[\"word\"]))\n",
    "\n",
    "# print the corresponding words that best predict an email as being spam\n",
    "for word_index in top_predicts:\n",
    "    print(word_index_dict.get(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions on our own email data\n",
    "\n",
    "Using our defined preprocessing functions above, and the vocabulary dictionary, we'll now read in some example spam and non-spam emails and make predictions using the SVM linear classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction 1 - non spam email example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Anyone knows how much it costs to host a web portal ?\n",
      ">\n",
      "Well, it depends on how many visitors you're expecting.\n",
      "This can be anywhere from less than 10 bucks a month to a couple of $100. \n",
      "You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \n",
      "if youre running something big..\n",
      "\n",
      "To unsubscribe yourself from this mailing list, send an email to:\n",
      "groupname-unsubscribe@egroups.com\n",
      "\n",
      "\n",
      "['anyon', 'know', 'how', 'much', 'it', 'cost', 'to', 'host', 'a', 'web', 'portal', 'well', 'it', 'depend', 'on', 'how', 'mani', 'visitor', 'you', 're', 'expect', 'thi', 'can', 'be', 'anywher', 'from', 'less', 'than', 'number', 'buck', 'a', 'month', 'to', 'a', 'coupl', 'of', 'dollarnumb', 'you', 'should', 'checkout', 'httpaddr', 'or', 'perhap', 'amazon', 'ecnumb', 'if', 'your', 'run', 'someth', 'big', 'to', 'unsubscrib', 'yourself', 'from', 'thi', 'mail', 'list', 'send', 'an', 'email', 'to', 'emailaddr']\n"
     ]
    }
   ],
   "source": [
    "f = open('machine-learning-ex6/ex6/emailSample1.txt','r')\n",
    "non_spam_example = f.read()\n",
    "f.close()\n",
    "nonspam_words = preprocess_email(non_spam_example)\n",
    "nonspam_word_vector, nonspam_feature_vector = vectorise_words(nonspam_words)\n",
    "\n",
    "print(non_spam_example)\n",
    "print(nonspam_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the non-spam example feature vector: 1899\n",
      "Number of non-zero entries: 45\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the non-spam example feature vector: {}\".format(len(nonspam_feature_vector)))\n",
    "\n",
    "print(\"Number of non-zero entries: {}\".format(\n",
    "    len([x for x in nonspam_feature_vector if x == 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonspam_feature_vector = np.array(nonspam_feature_vector)\n",
    "X_pred = nonspam_feature_vector.reshape(1, 1899)\n",
    "prediction = clf.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output label was predicted as '0', which corresponds to non-spam. This is correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction 2 - non spam email example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folks,\n",
      " \n",
      "my first time posting - have a bit of Unix experience, but am new to Linux.\n",
      "\n",
      " \n",
      "Just got a new PC at home - Dell box with Windows XP. Added a second hard disk\n",
      "for Linux. Partitioned the disk and have installed Suse 7.2 from CD, which went\n",
      "fine except it didn't pick up my monitor.\n",
      " \n",
      "I have a Dell branded E151FPp 15\" LCD flat panel monitor and a nVidia GeForce4\n",
      "Ti4200 video card, both of which are probably too new to feature in Suse's default\n",
      "set. I downloaded a driver from the nVidia website and installed it using RPM.\n",
      "Then I ran Sax2 (as was recommended in some postings I found on the net), but\n",
      "it still doesn't feature my video card in the available list. What next?\n",
      " \n",
      "Another problem. I have a Dell branded keyboard and if I hit Caps-Lock twice,\n",
      "the whole machine crashes (in Linux, not Windows) - even the on/off switch is\n",
      "inactive, leaving me to reach for the power cable instead.\n",
      " \n",
      "If anyone can help me in any way with these probs., I'd be really grateful -\n",
      "I've searched the 'net but have run out of ideas.\n",
      " \n",
      "Or should I be going for a different version of Linux such as RedHat? Opinions\n",
      "welcome.\n",
      " \n",
      "Thanks a lot,\n",
      "Peter\n",
      "\n",
      "-- \n",
      "Irish Linux Users' Group: ilug@linux.ie\n",
      "http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\n",
      "List maintainer: listmaster@linux.ie\n",
      "\n",
      "\n",
      "\n",
      "['folk', 'my', 'first', 'time', 'post', 'have', 'a', 'bit', 'of', 'unix', 'experi', 'but', 'am', 'new', 'to', 'linux', 'just', 'got', 'a', 'new', 'pc', 'at', 'home', 'dell', 'box', 'with', 'window', 'xp', 'ad', 'a', 'second', 'hard', 'disk', 'for', 'linux', 'partit', 'the', 'disk', 'and', 'have', 'instal', 'suse', 'number', 'number', 'from', 'cd', 'which', 'went', 'fine', 'except', 'it', 'didn', 't', 'pick', 'up', 'my', 'monitor', 'i', 'have', 'a', 'dell', 'brand', 'enumberfpp', 'number', 'lcd', 'flat', 'panel', 'monitor', 'and', 'a', 'nvidia', 'geforcenumb', 'tinumb', 'video', 'card', 'both', 'of', 'which', 'are', 'probabl', 'too', 'new', 'to', 'featur', 'in', 'suse', 's', 'default', 'set', 'i', 'download', 'a', 'driver', 'from', 'the', 'nvidia', 'websit', 'and', 'instal', 'it', 'use', 'rpm', 'then', 'i', 'ran', 'saxnumb', 'as', 'wa', 'recommend', 'in', 'some', 'post', 'i', 'found', 'on', 'the', 'net', 'but', 'it', 'still', 'doesn', 't', 'featur', 'my', 'video', 'card', 'in', 'the', 'avail', 'list', 'what', 'next', 'anoth', 'problem', 'i', 'have', 'a', 'dell', 'brand', 'keyboard', 'and', 'if', 'i', 'hit', 'cap', 'lock', 'twice', 'the', 'whole', 'machin', 'crash', 'in', 'linux', 'not', 'window', 'even', 'the', 'on', 'off', 'switch', 'is', 'inact', 'leav', 'me', 'to', 'reach', 'for', 'the', 'power', 'cabl', 'instead', 'if', 'anyon', 'can', 'help', 'me', 'in', 'ani', 'way', 'with', 'these', 'prob', 'i', 'd', 'be', 'realli', 'grate', 'i', 've', 'search', 'the', 'net', 'but', 'have', 'run', 'out', 'of', 'idea', 'or', 'should', 'i', 'be', 'go', 'for', 'a', 'differ', 'version', 'of', 'linux', 'such', 'as', 'redhat', 'opinion', 'welcom', 'thank', 'a', 'lot', 'peter', 'irish', 'linux', 'user', 'group', 'emailaddr', 'httpaddr', 'mailman', 'listinfo', 'ilug', 'for', 'un', 'subscript', 'inform', 'list', 'maintain', 'emailaddr']\n",
      "\n",
      "\n",
      "Length of the non-spam example feature vector: 1899\n",
      "Number of non-zero entries: 128\n"
     ]
    }
   ],
   "source": [
    "f = open('machine-learning-ex6/ex6/emailSample2.txt','r')\n",
    "non_spam_example = f.read()\n",
    "f.close()\n",
    "nonspam_words = preprocess_email(non_spam_example)\n",
    "nonspam_word_vector, nonspam_feature_vector = vectorise_words(nonspam_words)\n",
    "\n",
    "print(non_spam_example)\n",
    "print(nonspam_words)\n",
    "\n",
    "print(\"\\n\\nLength of the non-spam example feature vector: {}\".format(len(nonspam_feature_vector)))\n",
    "\n",
    "print(\"Number of non-zero entries: {}\".format(\n",
    "    len([x for x in nonspam_feature_vector if x == 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "nonspam_feature_vector = np.array(nonspam_feature_vector)\n",
    "X_pred = nonspam_feature_vector.reshape(1, 1899)\n",
    "prediction = clf.predict(X_pred)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output label is '0' again, which corresponds to non-spam. Correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction 3 - spam email example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do You Want To Make $1000 Or More Per Week?\n",
      "\n",
      " \n",
      "\n",
      "If you are a motivated and qualified individual - I \n",
      "will personally demonstrate to you a system that will \n",
      "make you $1,000 per week or more! This is NOT mlm.\n",
      "\n",
      " \n",
      "\n",
      "Call our 24 hour pre-recorded number to get the \n",
      "details.  \n",
      "\n",
      " \n",
      "\n",
      "000-456-789\n",
      "\n",
      " \n",
      "\n",
      "I need people who want to make serious money.  Make \n",
      "the call and get the facts. \n",
      "\n",
      "Invest 2 minutes in yourself now!\n",
      "\n",
      " \n",
      "\n",
      "000-456-789\n",
      "\n",
      " \n",
      "\n",
      "Looking forward to your call and I will introduce you \n",
      "to people like yourself who\n",
      "are currently making $10,000 plus per week!\n",
      "\n",
      " \n",
      "\n",
      "000-456-789\n",
      "\n",
      "\n",
      "\n",
      "3484lJGv6-241lEaN9080lRmS6-271WxHo7524qiyT5-438rjUv5615hQcf0-662eiDB9057dMtVl72\n",
      "\n",
      "\n",
      "['do', 'you', 'want', 'to', 'make', 'dollarnumb', 'or', 'more', 'per', 'week', 'if', 'you', 'are', 'a', 'motiv', 'and', 'qualifi', 'individu', 'i', 'will', 'person', 'demonstr', 'to', 'you', 'a', 'system', 'that', 'will', 'make', 'you', 'dollarnumb', 'number', 'per', 'week', 'or', 'more', 'thi', 'is', 'not', 'mlm', 'call', 'our', 'number', 'hour', 'pre', 'record', 'number', 'to', 'get', 'the', 'detail', 'number', 'number', 'number', 'i', 'need', 'peopl', 'who', 'want', 'to', 'make', 'seriou', 'money', 'make', 'the', 'call', 'and', 'get', 'the', 'fact', 'invest', 'number', 'minut', 'in', 'yourself', 'now', 'number', 'number', 'number', 'look', 'forward', 'to', 'your', 'call', 'and', 'i', 'will', 'introduc', 'you', 'to', 'peopl', 'like', 'yourself', 'who', 'are', 'current', 'make', 'dollarnumb', 'number', 'plu', 'per', 'week', 'number', 'number', 'number', 'numberljgvnumb', 'numberleannumberlrmsnumb', 'numberwxhonumberqiytnumb', 'numberrjuvnumberhqcfnumb', 'numbereidbnumberdmtvlnumb']\n",
      "\n",
      "\n",
      "Length of the non-spam example feature vector: 1899\n",
      "Number of non-zero entries: 48\n"
     ]
    }
   ],
   "source": [
    "f = open('machine-learning-ex6/ex6/spamSample1.txt','r')\n",
    "spam_example = f.read()\n",
    "f.close()\n",
    "spam_words = preprocess_email(spam_example)\n",
    "spam_word_vector, spam_feature_vector = vectorise_words(spam_words)\n",
    "\n",
    "print(spam_example)\n",
    "print(spam_words)\n",
    "\n",
    "print(\"\\n\\nLength of the non-spam example feature vector: {}\".format(len(spam_feature_vector)))\n",
    "\n",
    "print(\"Number of non-zero entries: {}\".format(\n",
    "    len([x for x in spam_feature_vector if x == 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "spam_feature_vector = np.array(spam_feature_vector)\n",
    "X_pred = spam_feature_vector.reshape(1, 1899)\n",
    "prediction = clf.predict(X_pred)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output label is '1', which is spam. Our model was correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction 4 - spam email example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Buy Viagra Generic Online\n",
      "\n",
      "Viagra 100mg x 60 Pills $125, Free Pills & Reorder Discount, Top Selling 100% Quality & Satisfaction guaranteed!\n",
      "\n",
      "We accept VISA, Master & E-Check Payments, 90000+ Satisfied Customers!\n",
      "http://medphysitcstech.ru\n",
      "\n",
      "\n",
      "\n",
      "['best', 'buy', 'viagra', 'gener', 'onlin', 'viagra', 'numbermg', 'x', 'number', 'pill', 'dollarnumb', 'free', 'pill', 'reorder', 'discount', 'top', 'sell', 'number', 'qualiti', 'satisfact', 'guarante', 'we', 'accept', 'visa', 'master', 'e', 'check', 'payment', 'number', 'satisfi', 'custom', 'httpaddr']\n",
      "\n",
      "\n",
      "Length of the non-spam example feature vector: 1899\n",
      "Number of non-zero entries: 19\n"
     ]
    }
   ],
   "source": [
    "f = open('machine-learning-ex6/ex6/spamSample2.txt','r')\n",
    "spam_example = f.read()\n",
    "f.close()\n",
    "spam_words = preprocess_email(spam_example)\n",
    "spam_word_vector, spam_feature_vector = vectorise_words(spam_words)\n",
    "\n",
    "print(spam_example)\n",
    "print(spam_words)\n",
    "\n",
    "print(\"\\n\\nLength of the non-spam example feature vector: {}\".format(len(spam_feature_vector)))\n",
    "\n",
    "print(\"Number of non-zero entries: {}\".format(\n",
    "    len([x for x in spam_feature_vector if x == 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "spam_feature_vector = np.array(spam_feature_vector)\n",
    "X_pred = spam_feature_vector.reshape(1, 1899)\n",
    "prediction = clf.predict(X_pred)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our model was successful in predicting '1', which corresponds to spam!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
